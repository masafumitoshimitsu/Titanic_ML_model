モデルの更新と比較を自動化するためには、モデルの更新が検出された場合に自動的にプログラムが実行される仕組みを構築することが重要です。以下では、CI/CDツールやクラウドサービスを使用して、このプロセスを自動化する方法を提案します。

### 1. GitHub Actionsによる自動化
GitHub Actionsは、リポジトリの変更をトリガーとしてCI/CDパイプラインを実行するための強力なツールです。

#### 手順
1. **リポジトリにモデルの更新スクリプトを追加**
   - モデルの更新スクリプト（上記のコード）をリポジトリに保存します。

2. **GitHub Actionsのワークフローファイルを作成**
   - `.github/workflows/update_model.yml`という名前で以下のようなワークフローファイルを作成します。

```yaml
name: Model Update and Comparison

on:
  push:
    branches:
      - main
  schedule:
    - cron: '0 0 * * *'  # 毎日実行するスケジュール

jobs:
  update-and-compare:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'

    - name: Install dependencies
      run: |
        python -m venv venv
        source venv/bin/activate
        pip install -r requirements.txt

    - name: Run model update and comparison
      run: |
        source venv/bin/activate
        python update_model.py
```

3. **update_model.pyを作成**
   - モデルの更新と比較を行うスクリプトを作成します。

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report
import mlflow
import mlflow.sklearn

def load_and_preprocess_data(url):
    data = pd.read_csv(url)
    data = data[['Survived', 'Pclass', 'Sex', 'Age', 'Fare']]
    data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})
    data = data.dropna()
    return data

def split_features_and_target(data):
    X = data.drop('Survived', axis=1)
    y = data['Survived']
    return X, y

def train_model(X_train, y_train):
    model = LogisticRegression(max_iter=1000)
    model.fit(X_train, y_train)
    return model

def evaluate_model(model, X_test, y_test):
    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    precision = precision_score(y_test, predictions)
    recall = recall_score(y_test, predictions)
    f1 = f1_score(y_test, predictions)
    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])
    report = classification_report(y_test, predictions)
    return accuracy, precision, recall, f1, roc_auc, report

def train_and_save_initial_model(url):
    data = load_and_preprocess_data(url)
    X, y = split_features_and_target(data)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    with mlflow.start_run():
        model = train_model(X_train, y_train)
        accuracy, precision, recall, f1, roc_auc, report = evaluate_model(model, X_test, y_test)
        
        mlflow.log_param("random_state", 42)
        mlflow.log_metric("accuracy", accuracy)
        mlflow.log_metric("precision", precision)
        mlflow.log_metric("recall", recall)
        mlflow.log_metric("f1_score", f1)
        mlflow.log_metric("roc_auc", roc_auc)
        
        mlflow.sklearn.log_model(model, "model")
        
        print("Initial model saved in run %s" % mlflow.active_run().info.run_uuid)
        return mlflow.active_run().info.run_uuid

def update_model(url):
    data = load_and_preprocess_data(url)
    X, y = split_features_and_target(data)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    with mlflow.start_run():
        new_model = train_model(X_train, y_train)
        new_accuracy, new_precision, new_recall, new_f1, new_roc_auc, new_report = evaluate_model(new_model, X_test, y_test)
        
        mlflow.log_param("random_state", 42)
        mlflow.log_metric("accuracy", new_accuracy)
        mlflow.log_metric("precision", new_precision)
        mlflow.log_metric("recall", new_recall)
        mlflow.log_metric("f1_score", new_f1)
        mlflow.log_metric("roc_auc", new_roc_auc)
        
        mlflow.sklearn.log_model(new_model, "model")
        
        print("New model saved in run %s" % mlflow.active_run().info.run_uuid)
        return mlflow.active_run().info.run_uuid, (new_accuracy, new_precision, new_recall, new_f1, new_roc_auc, new_report)

def compare_models(initial_run_id, new_run_id):
    initial_model = mlflow.sklearn.load_model(f"runs:/{initial_run_id}/model")
    new_model = mlflow.sklearn.load_model(f"runs:/{new_run_id}/model")
    
    url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
    data = load_and_preprocess_data(url)
    X, y = split_features_and_target(data)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    initial_metrics = evaluate_model(initial_model, X_test, y_test)
    new_metrics = evaluate_model(new_model, X_test, y_test)
    
    print("Initial Model Metrics")
    print("Accuracy: ", initial_metrics[0])
    print("Precision: ", initial_metrics[1])
    print("Recall: ", initial_metrics[2])
    print("F1 Score: ", initial_metrics[3])
    print("ROC AUC: ", initial_metrics[4])
    print(initial_metrics[5])
    
    print("New Model Metrics")
    print("Accuracy: ", new_metrics[0])
    print("Precision: ", new_metrics[1])
    print("Recall: ", new_metrics[2])
    print("F1 Score: ", new_metrics[3])
    print("ROC AUC: ", new_metrics[4])
    print(new_metrics[5])
    
    return initial_metrics, new_metrics

def main():
    url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
    
    # 初期モデルの訓練と保存
    initial_run_id = train_and_save_initial_model(url)
    
    # モデルの更新
    new_run_id, new_metrics = update_model(url)
    
    # モデルの性能比較
    initial_metrics, new_metrics = compare_models(initial_run_id, new_run_id)
    
    return initial_metrics, new_metrics

if __name__ == "__main__":
    initial_metrics, new_metrics = main()
```

### 2. Jenkinsによる自動化
Jenkinsは、オープンソースの自動化サーバーで、CI/CDパイプラインの構築に広く使われています。

#### 手順
1. **Jenkinsをセットアップ**: Jenkinsをインストールし、ジョブを設定します。
2. **ジョブの設定**: 新しいジョブを作成し、ソースコードリポジトリ（例：GitHub）からコードを取得するように設定します。
3. **ビルドステップの追加**: Jenkinsジョブのビルドステップに、以下のようなスクリプトを追加します。

```bash
#!/bin/bash

# 仮想環境のセットアップ
python3 -m venv venv
source venv/bin/activate

# 依存関係のインストール
pip install -r requirements.txt

# モデルの更新と比較スクリプトを実行
python update_model.py
```

4. **トリガー設定**: GitHubウェブフックやJenkinsのビルドトリガーを設定し、リポジトリの変更を検出した場合に自動的にジョブを実行します。
